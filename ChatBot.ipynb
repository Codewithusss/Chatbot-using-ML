{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTBOdU4QA1Q4JW6Dp/53uY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\" Deep learning is a subset of machine learning, and it works on the structure and functions similarly to the human brain. It learns from data that is \n","unstructured and uses complex algorithms to train a neural net.\n","Top Deep Learning Libraries\n","Keras\n","Theano\n","TensorFlow\n","DL4J\n","Torch\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"Vs8gv4cE21Dy","executionInfo":{"status":"ok","timestamp":1663995616217,"user_tz":-330,"elapsed":461,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"337e4aed-9f36-4e68-ec9c-7e40a1aa3f19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Deep learning is a subset of machine learning, and it works on the structure and functions similarly to the human brain. It learns from data that is \\nunstructured and uses complex algorithms to train a neural net.\\nTop Deep Learning Libraries\\nKeras\\nTheano\\nTensorFlow\\nDL4J\\nTorch\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["\"\"\" TensorFlow is an open-source library developed by Google primarily for deep learning applications.TensorFlow accepts data in the form of multi-dimensional \n","arrays of higher dimensions called tensors. Multi-dimensional arrays are very handy in handling large amounts of data.One of the major advantages of TensorFlow \n","is that it supports GPUs, as well as CPUs. It also has a faster compilation time than other deep learning libraries, like Keras and Torch.\n","\n","Arrays of data with varying dimensions and ranks that are fed as input to the neural network are called tensors.\n","\"\"\""],"metadata":{"id":"tHdyagUc3khH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" TFlearn is a high-level deep learning library built on the top of TensorFlow. It is modular and transparent. It offers excellent facilities and speeds up \n","experimentation. It is easy to use and understand. \n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"WXv-gBRk7yFF","executionInfo":{"status":"ok","timestamp":1663997002596,"user_tz":-330,"elapsed":390,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"b839908d-faf4-42a6-9643-24d341c00392"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' TFlearn is a high-level deep learning library built on the top of TensorFlow. It is modular and transparent. It offers excellent facilities and speeds up \\nexperimentation. It is easy to use and understand. \\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["pip install tflearn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzBhKrvFyAxg","executionInfo":{"status":"ok","timestamp":1663995264240,"user_tz":-330,"elapsed":3821,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"85233151-779f-4c7c-dffa-20868fcd2b3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.21.6)\n"]}]},{"cell_type":"code","source":["\"\"\" Python Random module is an in-built module of Python which is used to generate random numbers. These are pseudo-random numbers means these are not truly random. \n","Random numbers depend on the seeding value.\n","Json - Use the import function to import the JSON module. The JSON module is mainly used to convert the python dictionary above into a JSON string that \n","can be written into a file. While the JSON module will convert strings to Python datatypes, normally the JSON functions are used to read and write directly \n","from JSON files.\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"erXCmKm9_PyQ","executionInfo":{"status":"ok","timestamp":1663997863161,"user_tz":-330,"elapsed":375,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"3be1818f-0490-4629-eff0-70cd41cc87cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Python Random module is an in-built module of Python which is used to generate random numbers. These are pseudo-random numbers means these are not truly random. \\nRandom numbers depend on the seeding value.\\nJson - Use the import function to import the JSON module. The JSON module is mainly used to convert the python dictionary above into a JSON string that \\ncan be written into a file. While the JSON module will convert strings to Python datatypes, normally the JSON functions are used to read and write directly \\nfrom JSON files.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":60}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sjT__X6cgLca"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import tflearn\n","import random\n","import json"]},{"cell_type":"code","source":["\"\"\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical \n","resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, \n","wrappers for industrial-strength NLP libraries, and an active discussion forum.\n","A corpus is a large and structured set of machine-readable texts that have been produced in a natural communicative setting.\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"4I95fehXAHjn","executionInfo":{"status":"ok","timestamp":1663998124147,"user_tz":-330,"elapsed":13,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"8153c6cb-5777-4284-98d4-269c13fae761"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical \\nresources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, \\nwrappers for industrial-strength NLP libraries, and an active discussion forum.\\nA corpus is a large and structured set of machine-readable texts that have been produced in a natural communicative setting.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["\"\"\"Stemming is a natural language processing technique that lowers inflection in words to their root forms, hence aiding in the preprocessing of text, words, \n","and documents for text normalization.\n","\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"fsk4poB-Drqt","executionInfo":{"status":"ok","timestamp":1663998869508,"user_tz":-330,"elapsed":381,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"1061cd8f-e88e-4964-c934-9d97e39519a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Stemming is a natural language processing technique that lowers inflection in words to their root forms, hence aiding in the preprocessing of text, words, \\nand documents for text normalization.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.stem.lancaster import LancasterStemmer\n","stemmer = LancasterStemmer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZN5ftNGuhVvE","executionInfo":{"status":"ok","timestamp":1663995264245,"user_tz":-330,"elapsed":32,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"edd58e19-b4ea-49e8-f964-25f077b039fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.upload( )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"qQ9yyBRah8Ln","executionInfo":{"status":"ok","timestamp":1663995273589,"user_tz":-330,"elapsed":9367,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"41808bda-6983-478f-a8c4-95ffa334b704"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-fd4f35de-df2c-4242-8f57-28e79f5be142\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fd4f35de-df2c-4242-8f57-28e79f5be142\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving intents.json to intents.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'intents.json': b'{\"intents\": [\\r\\n  {\"tag\": \"greeting\",\\r\\n   \"patterns\": [\"Hi\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\"],\\r\\n   \"responses\": [\"Hello, thanks for visiting\", \"Good to see you again\", \"Hi there, how can I help?\"],\\r\\n   \"context_set\": \"\"\\r\\n  },\\r\\n  {\"tag\": \"goodbye\",\\r\\n   \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\\r\\n   \"responses\": [\"See you later, thanks for visiting\", \"Have a nice day\", \"Bye! Come back again soon.\"]\\r\\n  },\\r\\n  {\"tag\": \"thanks\",\\r\\n   \"patterns\": [\"Thanks\", \"Thank you\", \"That\\'s helpful\"],\\r\\n   \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\\r\\n  },\\r\\n  {\"tag\": \"hours\",\\r\\n   \"patterns\": [\"What hours are you open?\", \"What are your hours?\", \"When are you open?\" ],\\r\\n   \"responses\": [\"We\\'re open every day 9am-9pm\", \"Our hours are 9am-9pm every day\"]\\r\\n  },\\r\\n  {\"tag\": \"location\",\\r\\n   \"patterns\": [\"What is your location?\", \"Where are you located?\", \"What is your address?\", \"Where is your restaurant situated?\" ],\\r\\n   \"responses\": [\"We are on the intersection of London Alley and Bridge Avenue.\", \"We are situated at the intersection of London Alley and Bridge Avenue\", \"Our Address is: 1000 Bridge Avenue, London EC3N 4AJ, UK\"]\\r\\n  },\\r\\n  {\"tag\": \"payments\",\\r\\n   \"patterns\": [\"Do you take credit cards?\", \"Do you accept Mastercard?\", \"Are you cash only?\" ],\\r\\n   \"responses\": [\"We accept VISA, Mastercard and AMEX\", \"We accept most major credit cards\"]\\r\\n  },\\r\\n  {\"tag\": \"todaysmenu\",\\r\\n   \"patterns\": [\"What is your menu for today?\", \"What are you serving today?\", \"What is today\\'s special?\"],\\r\\n   \"responses\": [\"Today\\'s special is Chicken Tikka\", \"Our speciality for today is Chicken Tikka\"]\\r\\n  },\\r\\n  {\"tag\": \"deliveryoption\",\\r\\n   \"patterns\": [\"Do you provide home delivery?\", \"Do you deliver the food?\", \"What are the home delivery options?\" ],\\r\\n   \"responses\": [\"Yes, we provide home delivery through UBER Eats and Zomato?\", \"We have home delivery options through UBER Eats and Zomato\"],\\r\\n   \"context_set\": \"food\"\\r\\n  },\\r\\n  {\"tag\": \"menu\",\\r\\n   \"patterns\": [\"What is your Menu?\", \"What are the main course options?\", \"Can you tell me the most delicious dish from the menu?\", \"What is the today\\'s special?\"],\\r\\n   \"responses\": [\"You can visit www.mymenu.com for menu options\", \"You can check out the food menu at www.mymenu.com\", \"You can check various delicacies given in the food menu at www.mymenu.com\"],\\r\\n   \"context_filter\": \"food\"\\r\\n  }\\r\\n]\\r\\n}'}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["with open('intents.json') as json_data:\n","  intents = json.load(json_data)"],"metadata":{"id":"X6-4y63sq3Iw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["intents"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MZD0z0F35Pe","executionInfo":{"status":"ok","timestamp":1663995273591,"user_tz":-330,"elapsed":35,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"outputId":"0cf13f08-0496-48d7-8869-1b4bdbbcf9eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'intents': [{'tag': 'greeting',\n","   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n","   'responses': ['Hello, thanks for visiting',\n","    'Good to see you again',\n","    'Hi there, how can I help?'],\n","   'context_set': ''},\n","  {'tag': 'goodbye',\n","   'patterns': ['Bye', 'See you later', 'Goodbye'],\n","   'responses': ['See you later, thanks for visiting',\n","    'Have a nice day',\n","    'Bye! Come back again soon.']},\n","  {'tag': 'thanks',\n","   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n","   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n","  {'tag': 'hours',\n","   'patterns': ['What hours are you open?',\n","    'What are your hours?',\n","    'When are you open?'],\n","   'responses': [\"We're open every day 9am-9pm\",\n","    'Our hours are 9am-9pm every day']},\n","  {'tag': 'location',\n","   'patterns': ['What is your location?',\n","    'Where are you located?',\n","    'What is your address?',\n","    'Where is your restaurant situated?'],\n","   'responses': ['We are on the intersection of London Alley and Bridge Avenue.',\n","    'We are situated at the intersection of London Alley and Bridge Avenue',\n","    'Our Address is: 1000 Bridge Avenue, London EC3N 4AJ, UK']},\n","  {'tag': 'payments',\n","   'patterns': ['Do you take credit cards?',\n","    'Do you accept Mastercard?',\n","    'Are you cash only?'],\n","   'responses': ['We accept VISA, Mastercard and AMEX',\n","    'We accept most major credit cards']},\n","  {'tag': 'todaysmenu',\n","   'patterns': ['What is your menu for today?',\n","    'What are you serving today?',\n","    \"What is today's special?\"],\n","   'responses': [\"Today's special is Chicken Tikka\",\n","    'Our speciality for today is Chicken Tikka']},\n","  {'tag': 'deliveryoption',\n","   'patterns': ['Do you provide home delivery?',\n","    'Do you deliver the food?',\n","    'What are the home delivery options?'],\n","   'responses': ['Yes, we provide home delivery through UBER Eats and Zomato?',\n","    'We have home delivery options through UBER Eats and Zomato'],\n","   'context_set': 'food'},\n","  {'tag': 'menu',\n","   'patterns': ['What is your Menu?',\n","    'What are the main course options?',\n","    'Can you tell me the most delicious dish from the menu?',\n","    \"What is the today's special?\"],\n","   'responses': ['You can visit www.mymenu.com for menu options',\n","    'You can check out the food menu at www.mymenu.com',\n","    'You can check various delicacies given in the food menu at www.mymenu.com'],\n","   'context_filter': 'food'}]}"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["words = []\n","classes = []\n","documents = []\n","ignore = ['?']\n","# loop through each sentence in the intent's patterns\n","for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","        # tokenize each and every word in the sentence\n","        w = nltk.word_tokenize(pattern)\n","        # add word to the words list\n","        words.extend(w)\n","        # add word(s) to documents\n","        documents.append((w, intent['tag']))\n","        # add tags to our classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"],"metadata":{"id":"na5dcBt737Lu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform stemming and lower each word as well as remove duplicates\n","words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n","words = sorted(list(set(words)))\n","\n","# remove duplicate classes\n","classes = sorted(list(set(classes)))\n","\n","print (len(documents), \"documents\")\n","print (len(classes), \"classes\", classes)\n","print (len(words), \"unique stemmed words\", words)"],"metadata":{"id":"oFjs6ZrI4hp4","executionInfo":{"status":"ok","timestamp":1663995273593,"user_tz":-330,"elapsed":30,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"15ff8a60-ae74-4462-c6a4-644f427bcf58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["31 documents\n","9 classes ['deliveryoption', 'goodbye', 'greeting', 'hours', 'location', 'menu', 'payments', 'thanks', 'todaysmenu']\n","57 unique stemmed words [\"'s\", 'acceiv', 'address', 'anyon', 'ar', 'bye', 'can', 'card', 'cash', 'cours', 'credit', 'day', 'del', 'delicy', 'delivery', 'dish', 'do', 'food', 'for', 'from', 'good', 'goodby', 'hello', 'help', 'hi', 'hom', 'hour', 'how', 'is', 'lat', 'loc', 'main', 'mastercard', 'me', 'menu', 'most', 'on', 'op', 'opt', 'provid', 'resta', 'see', 'serv', 'situ', 'spec', 'tak', 'tel', 'thank', 'that', 'the', 'ther', 'today', 'what', 'when', 'wher', 'yo', 'you']\n"]}]},{"cell_type":"code","source":["# create training data\n","training = []\n","output = []\n","# create an empty array for output\n","output_empty = [0] * len(classes)\n","\n","# create training set, bag of words for each sentence\n","for doc in documents:\n","    # initialize bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # stemming each word\n","    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n","    # create bag of words array\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # output is '1' for current tag and '0' for rest of other tags\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])\n","\n","# shuffling features and turning it into np.array\n","random.shuffle(training)\n","training = np.array(training)\n","\n","# creating training lists\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])"],"metadata":{"id":"DNqxg-cR4tKR","executionInfo":{"status":"ok","timestamp":1663995273593,"user_tz":-330,"elapsed":22,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3104e87-515e-444a-fabd-a75e16ae287c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]}]},{"cell_type":"code","source":["from tensorflow.python.framework import ops\n","ops.reset_default_graph()"],"metadata":{"id":"AmAKBtUl47jQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.compat.v1.reset_default_graph()"],"metadata":{"id":"2yjmSHVYgYDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# resetting underlying graph data\n","ops.reset_default_graph()\n","\n","# Building neural network\n","net = tflearn.input_data(shape=[None, len(train_x[0])])\n","net = tflearn.fully_connected(net, 10)\n","net = tflearn.fully_connected(net, 10)\n","net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n","net = tflearn.regression(net)\n","\n","# Defining model and setting up tensorboard\n","model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n","\n","# Start training\n","model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n","model.save('model.tflearn')"],"metadata":{"id":"FzrBD_0A41HI","executionInfo":{"status":"ok","timestamp":1663995454804,"user_tz":-330,"elapsed":180602,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"59f170b6-02f4-43a4-c6c9-3e1e4cab4b42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.01452\u001b[0m\u001b[0m | time: 0.015s\n","| Adam | epoch: 1000 | loss: 0.01452 - acc: 0.9999 -- iter: 24/31\n","Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.01456\u001b[0m\u001b[0m | time: 0.024s\n","| Adam | epoch: 1000 | loss: 0.01456 - acc: 0.9999 -- iter: 31/31\n","--\n"]}]},{"cell_type":"code","source":["import pickle\n","pickle.dump({'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open(\"training_data\", \"wb\"))"],"metadata":{"id":"5XduJWWZ-B6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# restoring all the data structures\n","data = pickle.load( open( \"training_data\", \"rb\" ) )\n","words = data['words']\n","classes = data['classes']\n","train_x = data['train_x']\n","train_y = data['train_y']"],"metadata":{"id":"BTuKhPKo9LIJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('intents.json') as json_data:\n","    intents = json.load(json_data)"],"metadata":{"id":"JwEcPLmW9M2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_up_sentence(sentence):\n","    # tokenizing the pattern\n","    sentence_words = nltk.word_tokenize(sentence)\n","    # stemming each word\n","    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n","    return sentence_words\n","\n","# returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","def bow(sentence, words, show_details=False):\n","    # tokenizing the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # generating bag of words\n","    bag = [0]*len(words)  \n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s: \n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","\n","    return(np.array(bag))"],"metadata":{"id":"FAojSRJbGVww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ERROR_THRESHOLD = 0.30\n","def classify(sentence):\n","    # generate probabilities from the model\n","    results = model.predict([bow(sentence, words)])[0]\n","    # filter out predictions below a threshold\n","    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append((classes[r[0]], r[1]))\n","    # return tuple of intent and probability\n","    return return_list\n","\n","def response(sentence, userID='123', show_details=False):\n","    results = classify(sentence)\n","    # if we have a classification then find the matching intent tag\n","    if results:\n","        # loop as long as there are matches to process\n","        while results:\n","            for i in intents['intents']:\n","                # find a tag matching the first result\n","                if i['tag'] == results[0][0]:\n","                    # a random response from the intent\n","                    return print(random.choice(i['responses']))\n","\n","            results.pop(0)"],"metadata":{"id":"9tETgfOVJgoc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classify ( 'What are your hours of operation?' )"],"metadata":{"id":"BFR8bxaA_H8z","executionInfo":{"status":"ok","timestamp":1663995454809,"user_tz":-330,"elapsed":72,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b6bf527-c7c4-462b-d14b-811e452b27b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('hours', 0.99917835)]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["response('When are you open?') "],"metadata":{"id":"Ji69cuCBRbKy","executionInfo":{"status":"ok","timestamp":1663995454809,"user_tz":-330,"elapsed":69,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10296458-483e-4b83-ec7d-1eaa8f7b5b17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We're open every day 9am-9pm\n"]}]},{"cell_type":"code","source":["response('What is menu for today?')"],"metadata":{"id":"nA0GswRiRc_t","executionInfo":{"status":"ok","timestamp":1663995454810,"user_tz":-330,"elapsed":65,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"136ea804-229e-4169-d8c1-0efac3241f79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Our speciality for today is Chicken Tikka\n"]}]},{"cell_type":"code","source":["#Some of other context free responses.\n","response('Do you accept Credit Card?')"],"metadata":{"id":"7xCTHrWcRfMQ","executionInfo":{"status":"ok","timestamp":1663995454811,"user_tz":-330,"elapsed":62,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce03a7ee-0b60-43e7-c490-fb9657aa595d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We accept VISA, Mastercard and AMEX\n"]}]},{"cell_type":"code","source":["response('Where can we locate you?')"],"metadata":{"id":"q2i6b5PPRhjh","executionInfo":{"status":"ok","timestamp":1663995454811,"user_tz":-330,"elapsed":59,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"37c14607-089c-4672-9c57-b22901ff0534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We are on the intersection of London Alley and Bridge Avenue.\n"]}]},{"cell_type":"code","source":["response('That is helpful')"],"metadata":{"id":"wpH0mU7nRjEu","executionInfo":{"status":"ok","timestamp":1663995454812,"user_tz":-330,"elapsed":56,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"58a21152-33d5-45a2-a7a3-d3c674fdd675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Happy to help!\n"]}]},{"cell_type":"code","source":["response('Bye')"],"metadata":{"id":"9qJo-MHgRleL","executionInfo":{"status":"ok","timestamp":1663995454812,"user_tz":-330,"elapsed":52,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"96739804-746d-4654-f695-cf3217723928"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Have a nice day\n"]}]},{"cell_type":"code","source":["#Adding some context to the conversation i.e. Contexualization for altering question and intents etc.\n","# create a data structure to hold user context\n","context = {}\n","\n","ERROR_THRESHOLD = 0.25\n","def classify(sentence):\n","    # generate probabilities from the model\n","    results = model.predict([bow(sentence, words)])[0]\n","    # filter out predictions below a threshold\n","    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append((classes[r[0]], r[1]))\n","    # return tuple of intent and probability\n","    return return_list\n","\n","def response(sentence, userID='123', show_details=False):\n","    results = classify(sentence)\n","    # if we have a classification then find the matching intent tag\n","    if results:\n","        # loop as long as there are matches to process\n","        while results:\n","            for i in intents['intents']:\n","                # find a tag matching the first result\n","                if i['tag'] == results[0][0]:\n","                    # set context for this intent if necessary\n","                    if 'context_set' in i:\n","                        if show_details: print ('context:', i['context_set'])\n","                        context[userID] = i['context_set']\n","\n","                    # check if this intent is contextual and applies to this user's conversation\n","                    if not 'context_filter' in i or \\\n","                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n","                        if show_details: print ('tag:', i['tag'])\n","                        # a random response from the intent\n","                        return print(random.choice(i['responses']))\n","\n","            results.pop(0)"],"metadata":{"id":"gI1rQtmvR73d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response('Can you please let me know the delivery options?')"],"metadata":{"id":"IKfH7jNDR_ad","executionInfo":{"status":"ok","timestamp":1663995454814,"user_tz":-330,"elapsed":49,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c814739-95ed-48b9-979b-c6ee474921b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Today's special is Chicken Tikka\n"]}]},{"cell_type":"code","source":["response('What is menu for today?')"],"metadata":{"id":"rHfa47auSCeg","executionInfo":{"status":"ok","timestamp":1663995454815,"user_tz":-330,"elapsed":46,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"44af9741-f487-4c42-a0ef-b93a97d49332"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Today's special is Chicken Tikka\n"]}]},{"cell_type":"code","source":["context"],"metadata":{"id":"mVlfzr5gSES4","executionInfo":{"status":"ok","timestamp":1663995454816,"user_tz":-330,"elapsed":44,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7783e430-bf62-49e2-b4bc-fc6bbcaf9d74"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{}"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["response(\"Hi there!\", show_details=True)"],"metadata":{"id":"bV27r1V1SGXl","executionInfo":{"status":"ok","timestamp":1663995454817,"user_tz":-330,"elapsed":41,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec826ce7-5f6f-4935-898e-eee8c16ffd51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["context: \n","tag: greeting\n","Hi there, how can I help?\n"]}]},{"cell_type":"code","source":["response('What is menu for today?')"],"metadata":{"id":"FY7dZ2HKSIS-","executionInfo":{"status":"ok","timestamp":1663995454817,"user_tz":-330,"elapsed":38,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf787d9f-ed9f-4b63-cb1f-8e4cf014e826"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Our speciality for today is Chicken Tikka\n"]}]},{"cell_type":"code","source":["response('What is todays speciality?',show_details=True)"],"metadata":{"id":"uLun9N7ciMq1","executionInfo":{"status":"ok","timestamp":1663995454818,"user_tz":-330,"elapsed":35,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47fac1b8-0255-4da0-c5aa-6109bad80941"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tag: todaysmenu\n","Our speciality for today is Chicken Tikka\n"]}]},{"cell_type":"code","source":["response('Menu?',show_details=True)"],"metadata":{"id":"TBJcIzgsih1T","executionInfo":{"status":"ok","timestamp":1663995454818,"user_tz":-330,"elapsed":30,"user":{"displayName":"KOMAL PATIL","userId":"12123875425062086412"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2319c326-393d-4b3b-da46-ffb0eb340c56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["context: \n","tag: greeting\n","Hello, thanks for visiting\n"]}]}]}